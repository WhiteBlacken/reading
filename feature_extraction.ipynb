{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "gaze = pd.read_csv('gaze_1017.csv')\n",
    "# 数据的样式\n",
    "gaze.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              gaze_x  \\\n0  499.9281916929646,500.7827776075044,505.779561...   \n1  500.0809183161369,501.2473190313305,505.520843...   \n2  976.0934688438953,940.3889573899594,902.095533...   \n3  500.11682246965455,500.8400332489199,502.42095...   \n4  499.94855524272094,503.02118947543767,506.5767...   \n\n                                              gaze_y  \\\n0  500.01446883798474,499.7674575377377,499.27408...   \n1  499.94212464806105,500.00284609397926,501.3383...   \n2  427.87624362040066,394.97962288910423,441.4959...   \n3  500.08466949635516,499.9072253333237,499.27497...   \n4  500.1119995236597,500.8045022214369,500.412437...   \n\n                                              gaze_t  \n0  15.5,1094.5,1138.7999999523163,1167.1999999284...  \n1  18.899999999441206,7789.5,7835.700000000186,78...  \n2  16466.39999999944,16784.299999999814,16853.299...  \n3  23.299999999813735,1134.0999999996275,1188.399...  \n4  15.699999999254942,1119.1000000014901,1164.900...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gaze_x</th>\n      <th>gaze_y</th>\n      <th>gaze_t</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>499.9281916929646,500.7827776075044,505.779561...</td>\n      <td>500.01446883798474,499.7674575377377,499.27408...</td>\n      <td>15.5,1094.5,1138.7999999523163,1167.1999999284...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>500.0809183161369,501.2473190313305,505.520843...</td>\n      <td>499.94212464806105,500.00284609397926,501.3383...</td>\n      <td>18.899999999441206,7789.5,7835.700000000186,78...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>976.0934688438953,940.3889573899594,902.095533...</td>\n      <td>427.87624362040066,394.97962288910423,441.4959...</td>\n      <td>16466.39999999944,16784.299999999814,16853.299...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>500.11682246965455,500.8400332489199,502.42095...</td>\n      <td>500.08466949635516,499.9072253333237,499.27497...</td>\n      <td>23.299999999813735,1134.0999999996275,1188.399...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>499.94855524272094,503.02118947543767,506.5767...</td>\n      <td>500.1119995236597,500.8045022214369,500.412437...</td>\n      <td>15.699999999254942,1119.1000000014901,1164.900...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 滤波器，用于生成label\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data = signal.medfilt(data, kernel_size=7)\n",
    "    data = signal.medfilt(data, kernel_size=7)\n",
    "    data = meanFilter(data, 5)\n",
    "    data = meanFilter(data, 5)\n",
    "    return data\n",
    "\n",
    "def meanFilter(data, win):\n",
    "    length = len(data)\n",
    "    res = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        s, n = 0, 0\n",
    "        for j in range(i - win // 2, i + win - win // 2):\n",
    "            if j < 0 or j >= length:\n",
    "                continue\n",
    "            else:\n",
    "                s += data[j]\n",
    "                n += 1\n",
    "        res[i] = s / n\n",
    "    return res\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# 抽取每次记录的前300个gaze （之后要处理可变长）\n",
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "cnt = 0\n",
    "for i,item in enumerate(gaze['gaze_x']):\n",
    "    if not pd.isnull(item):\n",
    "        gaze_x = item.split(',')\n",
    "        gaze_x = list(map(float,gaze_x))\n",
    "        if len(gaze_x)>300:\n",
    "            gaze_x = gaze_x[0:300]\n",
    "            if i%10 == 0:\n",
    "                test_data.append(gaze_x)\n",
    "                test_label.append(preprocess_data(gaze_x))\n",
    "            else:\n",
    "                train_data.append(gaze_x)\n",
    "                train_label.append(preprocess_data(gaze_x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "(<__main__.GetLoader at 0x1e6808c0c88>, <__main__.GetLoader at 0x1e6834878c8>)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 定义GetLoader类，继承Dataset方法，并重写__getitem__()和__len__()方法\n",
    "class GetLoader(Dataset):\n",
    "\t# 初始化函数，得到数据\n",
    "    def __init__(self, data_root, data_label):\n",
    "        self.data = data_root\n",
    "        self.label = data_label\n",
    "    # index是根据batchsize划分数据后得到的索引，最后将data和对应的labels进行一起返回\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        labels = self.label[index]\n",
    "        return data, labels\n",
    "    # 该函数返回数据大小长度，目的是DataLoader方便划分，如果不知道大小，DataLoader会一脸懵逼\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "source_data = np.array(train_data)\n",
    "\n",
    "source_label = np.array(train_label)\n",
    "# 通过GetLoader将数据进行加载，返回Dataset对象，包含data和labels\n",
    "train_dataset = GetLoader(source_data, source_label)\n",
    "test_dataset = GetLoader(np.array(test_data),np.array(test_label))\n",
    "train_dataset,test_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 个Batch \n",
      "[tensor([[ 926.0704,  907.0727,  844.4589,  ...,  358.2976,  276.4622,\n",
      "          286.8681],\n",
      "        [ 783.2406,  771.6726,  750.8606,  ...,  694.7237,  768.8643,\n",
      "          789.4265],\n",
      "        [ 904.9043,  872.6360,  783.2129,  ...,  874.1408,  880.9165,\n",
      "          871.2505],\n",
      "        [1098.1707,  949.9972,  815.7106,  ..., 1039.5199, 1130.0296,\n",
      "         1253.6942],\n",
      "        [ 479.5659,  528.3553,  565.7857,  ...,  389.3262,  348.4798,\n",
      "          373.9577],\n",
      "        [ 500.3960,  503.3709,  505.0346,  ...,  357.4613,  378.3938,\n",
      "          408.3999]], dtype=torch.float64), tensor([[798.4997, 786.0494, 767.1928,  ..., 409.1325, 378.0452, 350.7551],\n",
      "        [768.7918, 772.0141, 774.9058,  ..., 693.3816, 694.1319, 694.4607],\n",
      "        [775.2947, 777.4752, 782.0750,  ..., 869.4489, 872.0211, 871.9585],\n",
      "        [709.5220, 695.1157, 678.4696,  ..., 989.3775, 991.9586, 994.1525],\n",
      "        [535.3944, 543.6415, 552.5287,  ..., 421.2012, 403.2377, 388.9295],\n",
      "        [500.3960, 500.3960, 500.0212,  ..., 377.2579, 374.9048, 372.9281]],\n",
      "       dtype=torch.float64)]\n",
      "第 1 个Batch \n",
      "[tensor([[1125.8495, 1116.3266, 1046.1458,  ...,  529.0658,  723.4201,\n",
      "         1060.9200],\n",
      "        [ 500.1908,  499.8358,  500.7089,  ...,  508.2878,  515.9825,\n",
      "          500.7655],\n",
      "        [-104.4305,  -27.6982,    9.8034,  ..., 1496.4479, 1520.5717,\n",
      "         1536.9307],\n",
      "        [1145.5635, 1146.3973, 1241.6089,  ..., 1115.6907, 1132.4342,\n",
      "         1201.7704],\n",
      "        [ 499.9212,  496.9521,  477.9006,  ...,  125.3745,  128.9617,\n",
      "          259.9121],\n",
      "        [ 500.2272,  501.1522,  505.5867,  ...,  312.4543,  297.1620,\n",
      "          272.8429]], dtype=torch.float64), tensor([[ 986.3186,  984.1624,  981.8337,  ...,  420.4629,  418.5255,\n",
      "          416.6213],\n",
      "        [ 490.8167,  488.4357,  485.4731,  ...,  438.3907,  442.0239,\n",
      "          444.5644],\n",
      "        [   5.7860,    7.6700,   10.0406,  ..., 1470.7577, 1474.0618,\n",
      "         1477.0521],\n",
      "        [1216.7526, 1238.0756, 1261.0812,  ..., 1095.7687, 1095.1333,\n",
      "         1094.0744],\n",
      "        [ 469.8960,  468.9082,  467.1088,  ...,   73.4947,   76.7098,\n",
      "           79.3534],\n",
      "        [ 505.3880,  507.4102,  509.5700,  ...,  314.4738,  309.1462,\n",
      "          303.4092]], dtype=torch.float64)]\n",
      "第 2 个Batch \n",
      "[tensor([[ 500.8510,  504.3787,  501.9218,  ..., 1391.6075, 1385.4408,\n",
      "         1423.0011],\n",
      "        [ 480.3541,  467.9961,  446.8033,  ..., 1082.0975, 1077.6350,\n",
      "         1083.6664],\n",
      "        [ 778.3560,  722.0816,  691.6775,  ...,  611.8352,  597.6184,\n",
      "          409.7449],\n",
      "        [ 499.9084,  498.7208,  493.1165,  ..., 1216.1109, 1235.4893,\n",
      "         1253.4159],\n",
      "        [ 774.4561,  633.3329,  468.5611,  ...,  428.2607,  369.2887,\n",
      "          274.9896],\n",
      "        [ 500.0981,  501.0810,  507.6049,  ...,  895.7823,  884.8192,\n",
      "          922.5676]], dtype=torch.float64), tensor([[ 501.1682,  503.1270,  505.7061,  ..., 1406.8743, 1403.7179,\n",
      "         1400.5408],\n",
      "        [ 427.4680,  424.4347,  419.2878,  ..., 1051.8663, 1051.8663,\n",
      "         1051.8663],\n",
      "        [ 707.5449,  714.7158,  721.5830,  ...,  697.4222,  637.5058,\n",
      "          591.5787],\n",
      "        [ 480.6527,  478.9763,  475.9373,  ..., 1195.8227, 1198.1990,\n",
      "         1199.2043],\n",
      "        [ 425.4530,  419.0201,  410.5582,  ...,  433.0478,  408.8590,\n",
      "          385.6977],\n",
      "        [ 513.0349,  525.9979,  546.6821,  ...,  891.1767,  892.3275,\n",
      "          891.7180]], dtype=torch.float64)]\n",
      "第 3 个Batch \n",
      "[tensor([[ 562.6103,  577.8011,  583.9082,  ...,  860.3388,  817.4988,\n",
      "          751.6842],\n",
      "        [ 620.8087,  607.7364,  574.0633,  ...,  458.6797,  512.8103,\n",
      "          531.0151],\n",
      "        [1325.3570, 1159.9753, 1045.5582,  ...,  491.9629,  483.1610,\n",
      "          474.5955],\n",
      "        [ 499.9041,  498.7399,  495.3725,  ..., 1034.1841, 1023.3417,\n",
      "         1043.9159],\n",
      "        [1184.3774, 1147.5666, 1176.3090,  ..., 1699.3990, 1745.4218,\n",
      "         1681.3443],\n",
      "        [ 970.4276,  969.5383,  972.7003,  ..., 1427.9563, 1420.1223,\n",
      "         1468.2188]], dtype=torch.float64), tensor([[ 580.8217,  584.1051,  587.0707,  ...,  870.3927,  851.8817,\n",
      "          836.1597],\n",
      "        [ 570.0043,  564.7691,  559.0634,  ...,  457.9987,  458.4531,\n",
      "          458.6797],\n",
      "        [ 816.8229,  798.6071,  771.2704,  ...,  475.3143,  476.6481,\n",
      "          476.4814],\n",
      "        [ 491.5303,  489.8196,  486.9028,  ..., 1023.7671, 1023.6659,\n",
      "         1023.5665],\n",
      "        [1173.3968, 1178.0695, 1182.6179,  ..., 1644.8519, 1648.2936,\n",
      "         1649.1487],\n",
      "        [ 950.6080,  948.6504,  946.1745,  ..., 1410.7143, 1411.9510,\n",
      "         1411.4432]], dtype=torch.float64)]\n",
      "第 4 个Batch \n",
      "[tensor([[ 499.9700,  499.9585,  502.1410,  ...,  647.0873,  628.7549,\n",
      "          624.5200],\n",
      "        [1507.8130, 1517.2111, 1462.8171,  ..., 1371.1320, 1365.2829,\n",
      "         1401.3625],\n",
      "        [ 499.9164,  504.3722,  510.9237,  ..., 1224.4200,  944.8715,\n",
      "          810.3109],\n",
      "        [ 139.0805,  183.8205,  197.7251,  ...,  753.2902,  778.5568,\n",
      "          783.4822],\n",
      "        [ 500.0096,  500.6804,  498.9047,  ..., 1364.9776, 1398.5889,\n",
      "         1368.7726],\n",
      "        [1315.2097, 1412.9704, 1530.4357,  ...,  943.4187,  950.5534,\n",
      "          928.6181]], dtype=torch.float64), tensor([[ 495.2111,  495.7433,  496.3270,  ...,  616.0764,  621.6783,\n",
      "          624.1365],\n",
      "        [1427.7013, 1424.3400, 1418.5825,  ..., 1397.1696, 1392.5092,\n",
      "         1387.9613],\n",
      "        [ 507.4965,  510.9207,  517.6162,  ..., 1083.9784, 1045.8522,\n",
      "         1013.2997],\n",
      "        [ 178.3362,  184.6178,  190.7373,  ...,  728.8557,  730.3811,\n",
      "          731.5372],\n",
      "        [ 499.3029,  499.5617,  499.8793,  ..., 1363.9292, 1364.8990,\n",
      "         1364.8941],\n",
      "        [1459.0026, 1482.9322, 1507.7084,  ...,  927.3999,  924.3656,\n",
      "          921.5393]], dtype=torch.float64)]\n",
      "第 5 个Batch \n",
      "[tensor([[1133.3341,  903.2101,  635.0192,  ...,  673.2718,  662.3971,\n",
      "          671.1602],\n",
      "        [ 500.2411,  500.9605,  498.2528,  ...,  429.9927,  485.7704,\n",
      "          482.7001],\n",
      "        [ 923.8829,  868.9256,  811.7264,  ..., 1676.1254, 1685.3705,\n",
      "         1711.4772],\n",
      "        [ 500.5370,  500.0063,  508.2096,  ...,  784.0521,  802.9481,\n",
      "          839.7411],\n",
      "        [ 957.9296,  870.7541,  821.6854,  ...,  739.1493,  761.7117,\n",
      "          808.3354],\n",
      "        [ 812.7258,  757.0179,  778.9049,  ..., 1378.9660, 1346.2179,\n",
      "         1342.1476]], dtype=torch.float64), tensor([[ 501.3509,  485.6600,  461.2960,  ...,  663.5635,  664.2730,\n",
      "          664.1207],\n",
      "        [ 496.2141,  496.1727,  496.0831,  ...,  386.8325,  383.8956,\n",
      "          381.0089],\n",
      "        [ 702.9649,  693.0793,  682.0253,  ..., 1669.8569, 1669.8384,\n",
      "         1669.6447],\n",
      "        [ 504.3291,  511.5101,  522.6908,  ...,  782.4468,  782.4536,\n",
      "          781.9207],\n",
      "        [ 813.4252,  815.4903,  815.4639,  ...,  702.9214,  707.9917,\n",
      "          712.4454],\n",
      "        [ 771.8616,  773.3680,  774.2719,  ..., 1387.7639, 1378.5049,\n",
      "         1369.6890]], dtype=torch.float64)]\n",
      "第 6 个Batch \n",
      "[tensor([[ 500.0214,  499.7882,  497.9974,  ..., 1700.7875, 1662.7338,\n",
      "         1656.5119],\n",
      "        [ 499.9486,  503.0212,  506.5767,  ...,  430.3737,  415.3162,\n",
      "          408.8788],\n",
      "        [ 499.9845,  500.6480,  501.9153,  ...,  428.8896,  448.6929,\n",
      "          442.5367],\n",
      "        [1283.5707, 1187.9486, 1087.1917,  ...,  684.6105,  696.6181,\n",
      "          691.9833],\n",
      "        [ 500.2583,  502.1508,  508.9947,  ...,  965.6620,  943.4919,\n",
      "          923.2836],\n",
      "        [ 470.6626,  483.8553,  463.4934,  ..., 1229.3190, 1214.4534,\n",
      "         1201.4392]], dtype=torch.float64), tensor([[ 498.0126,  498.4264,  499.0012,  ..., 1673.1016, 1671.8124,\n",
      "         1669.9206],\n",
      "        [ 503.9177,  504.4047,  504.8391,  ...,  507.6886,  477.9140,\n",
      "          453.7757],\n",
      "        [ 500.9661,  501.3801,  501.8607,  ...,  420.8923,  421.7574,\n",
      "          422.3753],\n",
      "        [1077.3937, 1088.4039, 1101.1332,  ...,  678.1280,  679.4492,\n",
      "          680.2862],\n",
      "        [ 509.5295,  513.7519,  523.3442,  ...,  954.6142,  951.3902,\n",
      "          947.8120],\n",
      "        [ 444.0907,  441.0986,  437.7411,  ..., 1213.2033, 1212.3695,\n",
      "         1211.2544]], dtype=torch.float64)]\n",
      "第 7 个Batch \n",
      "[tensor([[1034.1473,  989.4131,  932.7471,  ...,  814.5444,  889.9007,\n",
      "          890.7223],\n",
      "        [1207.2496, 1223.3538, 1217.7638,  ..., 1500.7239, 1502.2845,\n",
      "         1526.9808],\n",
      "        [ 499.7572,  499.6547,  499.0303,  ...,  983.2679,  986.3837,\n",
      "          991.8252],\n",
      "        [ 500.0718,  498.5284,  492.1662,  ..., 1746.9703, 1700.1020,\n",
      "         1708.6212],\n",
      "        [ 803.3443,  826.7796,  829.8760,  ...,  849.0368,  872.5741,\n",
      "          857.8376],\n",
      "        [ 822.4500,  816.7958,  919.6913,  ...,  877.5822,  855.1698,\n",
      "          867.2720]], dtype=torch.float64), tensor([[ 914.7190,  913.5623,  910.6801,  ...,  753.4374,  753.2945,\n",
      "          753.0564],\n",
      "        [1001.3954,  984.0625,  958.5939,  ..., 1468.9659, 1468.2949,\n",
      "         1468.2949],\n",
      "        [ 501.1867,  501.9638,  502.7381,  ...,  987.6291,  987.1641,\n",
      "          986.6301],\n",
      "        [ 483.6839,  481.1290,  477.0958,  ..., 1725.4411, 1722.9172,\n",
      "         1720.0577],\n",
      "        [ 803.0309,  802.3857,  801.3754,  ...,  837.9611,  837.9611,\n",
      "          837.9611],\n",
      "        [ 867.4334,  875.6358,  883.1763,  ...,  893.4425,  885.2020,\n",
      "          878.2299]], dtype=torch.float64)]\n",
      "第 8 个Batch \n",
      "[tensor([[ 499.5783,  500.1560,  497.8202,  ...,  481.7452,  483.4155,\n",
      "          471.9025],\n",
      "        [ 499.6892,  500.5440,  504.3595,  ...,  450.0009,  509.7068,\n",
      "          513.0201],\n",
      "        [1369.3737, 1406.5999, 1465.9106,  ...,  638.7395,  625.9886,\n",
      "          580.9977],\n",
      "        [ 500.6831,  488.0187,  472.7756,  ..., 1467.4633, 1470.6747,\n",
      "         1479.4677],\n",
      "        [1188.1413, 1147.6025, 1100.5531,  ...,  471.3734,  406.0550,\n",
      "          362.4618],\n",
      "        [ 499.7899,  497.3779,  493.2117,  ..., 1569.3895, 1579.4681,\n",
      "         1597.9538]], dtype=torch.float64), tensor([[ 491.1701,  490.5458,  489.5530,  ...,  480.2032,  479.8177,\n",
      "          479.1752],\n",
      "        [ 499.8184,  499.8298,  499.8367,  ...,  467.6146,  465.3172,\n",
      "          463.1798],\n",
      "        [1417.0407, 1423.1255, 1428.5863,  ...,  627.0383,  624.2971,\n",
      "          620.3330],\n",
      "        [ 474.2182,  476.2695,  478.3064,  ..., 1413.2744, 1416.0484,\n",
      "         1417.6507],\n",
      "        [1067.4102, 1063.4072, 1057.6146,  ...,  461.5699,  441.1000,\n",
      "          425.3579],\n",
      "        [ 487.1125,  486.3748,  483.9360,  ..., 1569.3895, 1569.3895,\n",
      "         1569.3895]], dtype=torch.float64)]\n",
      "第 9 个Batch \n",
      "[tensor([[ 202.5853,  238.3079,  302.9810,  ...,  682.0807,  700.2961,\n",
      "          710.8757],\n",
      "        [ 512.7089,  475.6687,  459.1401,  ...,  778.9927,  758.4750,\n",
      "          796.9242],\n",
      "        [ 500.3939,  503.1578,  504.6591,  ..., 1057.5953, 1074.6536,\n",
      "         1112.9566],\n",
      "        [ 500.2428,  500.1810,  501.3894,  ..., 1650.5764, 1661.5627,\n",
      "         1716.0404],\n",
      "        [ 500.2144,  502.2957,  508.3033,  ...,  908.3458,  864.3693,\n",
      "          714.6121],\n",
      "        [ 914.0515,  897.9005,  862.0774,  ..., 1361.8503, 1375.9377,\n",
      "         1382.5409]], dtype=torch.float64), tensor([[ 272.6963,  288.0242,  305.2983,  ...,  696.0540,  695.9240,\n",
      "          695.1703],\n",
      "        [ 449.4384,  449.9037,  450.3839,  ...,  755.8499,  756.8450,\n",
      "          757.7600],\n",
      "        [ 503.4278,  503.8505,  504.2149,  ..., 1071.9812, 1071.3131,\n",
      "         1070.1995],\n",
      "        [ 499.8733,  499.9626,  499.9645,  ..., 1625.7178, 1630.8250,\n",
      "         1634.1590],\n",
      "        [ 510.9785,  518.3581,  528.7064,  ...,  890.3077,  870.2988,\n",
      "          851.1454],\n",
      "        [ 831.0082,  828.2107,  824.9596,  ..., 1334.6900, 1335.8905,\n",
      "         1336.9248]], dtype=torch.float64)]\n",
      "第 10 个Batch \n",
      "[tensor([[ 499.6211,  499.6423,  500.5726,  ..., 1547.4127, 1559.2297,\n",
      "         1526.7581],\n",
      "        [ 500.4678,  501.6978,  494.4788,  ...,  814.0677,  748.2576,\n",
      "          719.1137],\n",
      "        [1175.3866, 1258.7118, 1314.4918,  ..., 1419.4100, 1456.4982,\n",
      "         1465.9966],\n",
      "        [ 904.3126,  876.6295,  813.0223,  ..., 1222.4753, 1176.9883,\n",
      "         1155.4014]], dtype=torch.float64), tensor([[ 499.7174,  499.7324,  499.5138,  ..., 1529.1607, 1528.6186,\n",
      "         1528.0640],\n",
      "        [ 486.6676,  486.6676,  486.6676,  ...,  749.5965,  747.5591,\n",
      "          744.8375],\n",
      "        [1256.6191, 1273.0400, 1289.2490,  ..., 1408.4434, 1406.7444,\n",
      "         1404.8259],\n",
      "        [ 807.2748,  807.5197,  807.8626,  ..., 1221.1374, 1211.6341,\n",
      "         1202.0520]], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "# 读取数据\n",
    "datas = DataLoader(train_dataset, batch_size=6, shuffle=True, drop_last=False, num_workers=0)\n",
    "\n",
    "# 观察batch是都切割正确\n",
    "for i, data in enumerate(datas):\n",
    "\t# i表示第几个batch， data表示该batch对应的数据，包含data和对应的labels\n",
    "    print(\"第 {} 个Batch \\n{}\".format(i, data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter_cnn(\n",
      "  (model): Sequential(\n",
      "    (0): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 创建模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "w = nn.Conv1d(in_channels=1,out_channels=1,kernel_size=(7,),stride=(1,),padding=3)\n",
    "# 卷积核初始为均值滤波\n",
    "ones=torch.Tensor([[[1/7,1/7,1/7,1/7,1/7,1/7,1/7]]])\n",
    "w.weight = torch.nn.Parameter(ones)\n",
    "w.bias = torch.nn.Parameter(torch.tensor([0.]))\n",
    "class Filter_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Filter_cnn, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            w,\n",
    "            nn.Linear(300,300)\n",
    "        )\n",
    "    def forward(self,input):\n",
    "        return self.model(input)\n",
    "\n",
    "net = Filter_cnn()\n",
    "print(net)\n",
    "writer = SummaryWriter('logs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss:  329967.423\n",
      "epoch: 50 training loss:  3185.387\n",
      "epoch: 100 training loss:  1219.601\n",
      "epoch: 150 training loss:  740.524\n",
      "epoch: 200 training loss:  527.971\n",
      "epoch: 250 training loss:  419.144\n",
      "label:\n",
      "tensor([[ 798.4997,  786.0494,  767.1928,  ...,  409.1325,  378.0452,\n",
      "          350.7551],\n",
      "        [ 707.5449,  714.7158,  721.5830,  ...,  697.4222,  637.5058,\n",
      "          591.5787],\n",
      "        [ 702.9649,  693.0793,  682.0253,  ..., 1669.8569, 1669.8384,\n",
      "         1669.6447],\n",
      "        [ 449.4384,  449.9037,  450.3839,  ...,  755.8499,  756.8450,\n",
      "          757.7600]], dtype=torch.float64)\n",
      "x after:\n",
      "tensor([[ 750.4197,  748.1860,  742.5190,  ...,  393.8701,  362.5598,\n",
      "          349.8388],\n",
      "        [ 692.5229,  695.5389,  716.5919,  ...,  728.8058,  678.2328,\n",
      "          620.9850],\n",
      "        [ 702.2181,  701.8402,  699.2031,  ..., 1673.9840, 1685.8821,\n",
      "         1677.7556],\n",
      "        [ 461.6297,  440.7369,  454.0815,  ...,  764.7730,  769.4628,\n",
      "          752.8448]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "import torch\n",
    "import torch.optim as optimizer\n",
    "# 定义损失函数和优化器\n",
    "criterion_loss = nn.MSELoss()\n",
    "opt = optimizer.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "Loss_list = []\n",
    "correct_list = []\n",
    "for epoch in range(300):\n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "    for i,data in enumerate(datas):\n",
    "        train_x,train_y = data\n",
    "\n",
    "        if i==len(datas)-1 and epoch == 299:\n",
    "            print(\"label:\")\n",
    "            print(train_y)\n",
    "\n",
    "        train_x = train_x.to(torch.float32)\n",
    "        train_y = train_y.to(torch.float32)\n",
    "        train_x = train_x.unsqueeze(dim=1)\n",
    "        outputs = net(train_x)\n",
    "\n",
    "        outputs = outputs.squeeze(dim=1)\n",
    "\n",
    "        if i==len(datas)-1 and epoch == 299:\n",
    "            print(\"x after:\")\n",
    "            print(outputs)\n",
    "\n",
    "\n",
    "        loss = criterion_loss(outputs,train_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        predicted = torch.max(outputs.data, 1)[1]\n",
    "        y = torch.max(train_y.data, 1)[1]\n",
    "        running_loss += loss.item()\n",
    "        correct += (predicted == y).sum()\n",
    "    epoch_loss = running_loss/len(datas)\n",
    "    Loss_list.append(running_loss / len(datas))\n",
    "    correct_list.append(correct / len(datas))\n",
    "    loss = criterion_loss(outputs,train_y)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"epoch: {epoch} training loss: {epoch_loss: .3f}\")\n",
    "    writer.add_scalar(\"train loss\",running_loss / len(datas),epoch)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:\n",
      "tensor([[ 816.8229,  798.6071,  771.2704,  ...,  475.3143,  476.6481,\n",
      "          476.4814],\n",
      "        [1256.6191, 1273.0400, 1289.2490,  ..., 1408.4434, 1406.7444,\n",
      "         1404.8259],\n",
      "        [ 499.7174,  499.7324,  499.5138,  ..., 1529.1607, 1528.6186,\n",
      "         1528.0640],\n",
      "        [ 798.4997,  786.0494,  767.1928,  ...,  409.1325,  378.0452,\n",
      "          350.7551]], dtype=torch.float64)\n",
      "x after:\n",
      "tensor([[ 823.1852,  826.0172,  788.5513,  ...,  463.2715,  471.3351,\n",
      "          452.9034],\n",
      "        [1251.1157, 1294.8629, 1300.1082,  ..., 1428.9242, 1429.8142,\n",
      "         1399.0632],\n",
      "        [ 498.1505,  516.4996,  508.9467,  ..., 1541.8059, 1547.9756,\n",
      "         1533.6595],\n",
      "        [ 752.5118,  762.9453,  739.9536,  ...,  403.3554,  371.6489,\n",
      "          349.5734]], grad_fn=<SqueezeBackward1>)\n",
      "test loss:  313.793\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "Loss_list = []\n",
    "correct_list = []\n",
    "\n",
    "correct = 0\n",
    "running_loss = 0\n",
    "test_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True, drop_last=False, num_workers=0)\n",
    "origin_gaze = []\n",
    "filter_gaze = []\n",
    "for i,data in enumerate(test_dataloader):\n",
    "    train_x,train_y = data\n",
    "\n",
    "    if i == len(test_dataloader)-1:\n",
    "        print(\"label:\")\n",
    "        print(train_y)\n",
    "        orgin_gaze = train_y\n",
    "\n",
    "    train_x = train_x.to(torch.float32)\n",
    "    train_y = train_y.to(torch.float32)\n",
    "    train_x = train_x.unsqueeze(dim=1)\n",
    "    outputs = net(train_x)\n",
    "\n",
    "    outputs = outputs.squeeze(dim=1)\n",
    "\n",
    "    if i == len(test_dataloader)-1:\n",
    "        print(\"x after:\")\n",
    "        print(outputs)\n",
    "        filter_gaze = outputs\n",
    "\n",
    "\n",
    "    loss = criterion_loss(outputs,train_y)\n",
    "\n",
    "    predicted = torch.max(outputs.data, 1)[1]\n",
    "    y = torch.max(train_y.data, 1)[1]\n",
    "    running_loss += loss.item()\n",
    "    correct += (predicted == y).sum()\n",
    "epoch_loss = running_loss/len(datas)\n",
    "Loss_list.append(running_loss / len(datas))\n",
    "correct_list.append(correct / len(datas))\n",
    "loss = criterion_loss(outputs,train_y)\n",
    "\n",
    "print(f\"test loss: {epoch_loss: .3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "gaze_x = gaze['gaze_x'][0]\n",
    "gaze_y = gaze['gaze_y'][0]\n",
    "gaze_t = gaze['gaze_t'][0]\n",
    "print(type(gaze_x))\n",
    "print(type(gaze_y))\n",
    "print(type(gaze_t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "[15.5,\n 1094.5,\n 1138.7999999523163,\n 1167.1999999284744,\n 1208.6000000238419,\n 1235.5,\n 1268.6999999284744,\n 1302.0,\n 1335.1999999284744,\n 1368.7999999523163,\n 1405.8999999761581,\n 1434.3999999761581,\n 1471.7999999523163,\n 1501.8999999761581,\n 1538.1000000238419,\n 1565.5,\n 1593.1000000238419,\n 1619.1000000238419,\n 1653.0,\n 1682.1999999284744,\n 1710.0,\n 1734.5,\n 1765.1000000238419,\n 1786.2999999523163,\n 1814.8999999761581,\n 1841.6000000238419,\n 1866.1999999284744,\n 1892.6999999284744,\n 1915.1999999284744,\n 1938.5,\n 1968.8999999761581,\n 2002.1000000238419,\n 2037.7999999523163,\n 2067.600000023842,\n 2101.100000023842,\n 2137.399999976158,\n 2168.6999999284744,\n 2205.1999999284744,\n 2234.600000023842,\n 2281.6999999284744,\n 2331.7999999523163,\n 2403.0,\n 2433.7999999523163,\n 2481.7999999523163,\n 2548.399999976158,\n 2598.399999976158,\n 2648.399999976158,\n 2701.2999999523163,\n 2764.5,\n 2835.1999999284744,\n 2867.100000023842,\n 2914.2999999523163,\n 2935.2999999523163,\n 2971.899999976158,\n 3001.100000023842,\n 3034.100000023842,\n 3068.399999976158,\n 3101.600000023842,\n 3130.6999999284744,\n 3153.0,\n 3180.6999999284744,\n 3204.399999976158,\n 3235.1999999284744,\n 3266.899999976158,\n 3308.600000023842,\n 3333.0,\n 3384.899999976158,\n 3414.399999976158,\n 3442.5,\n 3466.2999999523163,\n 3501.2999999523163,\n 3531.100000023842,\n 3554.600000023842,\n 3580.6999999284744,\n 3605.6999999284744,\n 3630.399999976158,\n 3651.399999976158,\n 3672.899999976158,\n 3696.899999976158,\n 3717.5,\n 3747.2999999523163,\n 3768.2999999523163,\n 3790.5,\n 3813.600000023842,\n 3834.899999976158,\n 3858.0,\n 3880.100000023842,\n 3901.100000023842,\n 3934.6999999284744,\n 3980.1999999284744,\n 4004.6999999284744,\n 4031.0,\n 4057.0,\n 4116.899999976158,\n 4139.5,\n 4169.699999928474,\n 4199.899999976158,\n 4236.199999928474,\n 4267.100000023842,\n 4299.699999928474,\n 4351.199999928474,\n 4379.899999976158,\n 4403.299999952316,\n 4430.199999928474,\n 4452.600000023842,\n 4479.699999928474,\n 4505.5,\n 4530.0,\n 4554.399999976158,\n 4579.799999952316,\n 4604.699999928474,\n 4629.600000023842,\n 4651.100000023842,\n 4672.600000023842,\n 4696.299999952316,\n 4752.299999952316,\n 4783.699999928474,\n 4803.399999976158,\n 4834.199999928474,\n 4863.5,\n 4888.5,\n 4913.399999976158,\n 4949.799999952316,\n 4983.199999928474,\n 5019.0,\n 5083.600000023842,\n 5112.699999928474,\n 5150.299999952316,\n 5179.899999976158,\n 5216.600000023842,\n 5245.699999928474,\n 5279.100000023842,\n 5305.199999928474,\n 5331.100000023842,\n 5362.5,\n 5386.199999928474,\n 5412.799999952316,\n 5441.100000023842,\n 5466.0,\n 5495.799999952316,\n 5531.5,\n 5579.399999976158,\n 5612.299999952316,\n 5635.600000023842,\n 5662.399999976158,\n 5686.799999952316,\n 5712.100000023842,\n 5735.699999928474,\n 5762.299999952316,\n 5795.5,\n 5818.699999928474,\n 5845.399999976158,\n 5869.399999976158,\n 5895.600000023842,\n 5919.5,\n 5945.299999952316,\n 5966.199999928474,\n 5997.899999976158,\n 6028.899999976158,\n 6052.299999952316,\n 6085.199999928474,\n 6115.799999952316,\n 6145.399999976158,\n 6169.600000023842,\n 6195.600000023842,\n 6221.100000023842,\n 6245.199999928474,\n 6267.100000023842,\n 6295.600000023842,\n 6330.299999952316,\n 6378.799999952316,\n 6412.199999928474,\n 6435.299999952316,\n 6466.100000023842,\n 6498.299999952316,\n 6535.799999952316,\n 6565.0,\n 6602.100000023842,\n 6632.299999952316,\n 6664.699999928474,\n 6698.5,\n 6728.199999928474,\n 6753.199999928474,\n 6778.799999952316,\n 6800.5,\n 6832.600000023842,\n 6861.699999928474,\n 6888.100000023842,\n 6911.399999976158,\n 6935.799999952316,\n 6961.600000023842,\n 6986.299999952316,\n 7011.600000023842,\n 7034.299999952316,\n 7061.299999952316,\n 7089.799999952316,\n 7115.799999952316,\n 7149.0,\n 7178.5,\n 7201.199999928474,\n 7228.299999952316,\n 7251.899999976158,\n 7277.799999952316,\n 7301.799999952316,\n 7327.899999976158,\n 7353.299999952316,\n 7378.199999928474,\n 7403.199999928474,\n 7427.899999976158,\n 7454.299999952316,\n 7478.0,\n 7505.5,\n 7528.100000023842,\n 7565.299999952316,\n 7594.699999928474,\n 7619.899999976158,\n 7644.5,\n 7673.5,\n 7694.600000023842,\n 7716.0,\n 7748.600000023842,\n 7778.5,\n 7805.899999976158,\n 7828.899999976158,\n 7849.899999976158,\n 7881.0,\n 7911.299999952316,\n 7936.199999928474,\n 7967.399999976158,\n 7994.0,\n 8018.199999928474,\n 8044.0,\n 8067.899999976158,\n 8097.899999976158,\n 8127.399999976158,\n 8154.699999928474,\n 8179.600000023842,\n 8214.899999976158,\n 8244.5,\n 8277.600000023842,\n 8303.199999928474,\n 8327.799999952316,\n 8353.399999976158,\n 8379.199999928474,\n 8404.5,\n 8427.100000023842,\n 8449.0,\n 8481.399999976158,\n 8510.399999976158,\n 8536.399999976158,\n 8560.399999976158,\n 8582.199999928474,\n 8614.100000023842,\n 8636.399999976158,\n 8665.299999952316,\n 8694.199999928474,\n 8720.5,\n 8744.299999952316,\n 8767.0,\n 8793.899999976158,\n 8815.0,\n 8843.399999976158,\n 8867.799999952316,\n 8893.899999976158,\n 8917.0,\n 8943.399999976158,\n 8968.5,\n 8993.5,\n 9016.0,\n 9047.699999928474,\n 9077.199999928474,\n 9102.100000023842,\n 9126.899999976158,\n 9153.600000023842,\n 9176.600000023842,\n 9205.600000023842,\n 9227.799999952316,\n 9250.600000023842,\n 9280.5,\n 9310.100000023842,\n 9335.0,\n 9360.199999928474,\n 9385.899999976158,\n 9409.799999952316,\n 9447.600000023842,\n 9476.5,\n 9501.5,\n 9526.600000023842,\n 9552.699999928474,\n 9576.399999976158,\n 9601.299999952316,\n 9626.600000023842,\n 9650.399999976158,\n 9676.100000023842,\n 9706.5,\n 9729.100000023842,\n 9765.699999928474,\n 9796.299999952316,\n 9830.699999928474,\n 9869.600000023842]"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(gaze):\n",
    "    gaze = list(map(float,gaze))\n",
    "    gaze = gaze[0:300]\n",
    "    return gaze\n",
    "gaze_x = process(gaze_x)\n",
    "gaze_y = process(gaze_y)\n",
    "gaze_t = process(gaze_t)\n",
    "gaze_t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def get_result(gaze):\n",
    "    gaze = torch.tensor(gaze)\n",
    "    gaze=gaze.unsqueeze(dim=0)\n",
    "    gaze=gaze.unsqueeze(dim=0)\n",
    "    outputs = net(gaze)\n",
    "    return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'gaze_x':gaze_x,\n",
    "    'gaze_y':gaze_y,\n",
    "    'gaze_t':gaze_t,\n",
    "    'gaze_x_cnn':get_result(gaze_x).squeeze().detach().numpy(),\n",
    "    'gaze_y_cnn':get_result(gaze_y).squeeze().detach().numpy(),\n",
    "    'gaze_t_cnn':get_result(gaze_t).squeeze().detach().numpy(),\n",
    "    'gaze_x_filter':preprocess_data(gaze_x),\n",
    "    'gaze_y_filter':preprocess_data(gaze_x),\n",
    "    \n",
    "})\n",
    "\n",
    "path = \"static\\\\data\\\\dataset\\\\cnn.csv\"\n",
    "df.to_csv(path, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}